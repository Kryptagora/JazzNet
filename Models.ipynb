{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08516d18-3428-4e31-a738-a9a96eaa1ddd",
   "metadata": {},
   "source": [
    "# 3. Models\n",
    "This notebook contains the Network Architectures and Data Evaluation Systems for the BA Thesis. The data from the dataset is already processed in the notebook `PreProcessing.ipnb` and saved to `data/processed/chords.json`. Also, some Statistics can be found there. If there is any concern how the data has been processed, look into the notebook - all is done there. It also uses functions from `functions/utils.py`, such that the code is more readable and not cluttured. \n",
    "\n",
    "**Brief Overview Of this Notebook:**\n",
    "\n",
    "1. **Data Preparation**: Load the data from `chords.json`, add start/end tokens, padd them, split it into training and validation sets, and create data loaders.\n",
    "2. **Model Building (GRU)**: Define the GRU-based RNN architecture.\n",
    "3. **Model Building (LSTM)**: Define the LSTM-based RNN architecture.\n",
    "4. **Results**: Look at generated Data and Discuss it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cdfe1-837a-480a-a20a-cb869abbd243",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "### 1.1 Load Chords from Dataset\n",
    "Load chords from file `chords.data` in a json like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfc086b-4119-443f-8479-0939c8a8605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports \n",
    "import torch.nn as nn\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import pretty_midi\n",
    "from functions.utils import add_start_end_tokens\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3fba7d6-1c25-4cd5-be12-7334f0263f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', 'A:hdim7', 'A:hdim7', 'D:7', 'D:7', 'G:min7', 'G:min7', 'C:7', 'C:7', 'B:maj7', 'B:maj7', 'C:hdim7', 'F:7', 'B-:maj7', 'B-:maj7', 'B-:maj7', 'B-:maj7', 'B:min7', 'B:min7', 'E:7', 'E:7', 'A:maj7', 'A:maj7', 'F#:min7', 'F#:min7', 'E-:hdim7', 'E-:hdim7', 'A-:7', 'A-:7', 'D-:maj7', 'D-:maj7', 'D-:maj7', 'D-:maj7', 'C:7', 'C:7', 'B:7', 'B:7', 'B-:maj7', 'B-:maj7', 'B-:maj7', 'B-:maj7', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "def load_chords(file_path):\n",
    "    \"\"\"\n",
    "    Loads chords from a file and returns them as a 2D list.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read the entire file as a string\n",
    "        data_str = file.read()\n",
    "        \n",
    "        # Convert the string representation of lists into actual lists using json.loads\n",
    "        chords_2d_list = json.loads(data_str)\n",
    "        \n",
    "    return chords_2d_list\n",
    "\n",
    "all_chords = load_chords(\"data/processed/chords.json\")\n",
    "\n",
    "# add start and end tokens to data\n",
    "all_chords = add_start_end_tokens(all_chords)\n",
    "print(all_chords[0])  # Displaying the first chord sequence for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94b1a0-e5b0-4263-9b7d-f6cc60088059",
   "metadata": {},
   "source": [
    "### 1.2 Examine the Data\n",
    "Getting used to the data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b60d6b6-48ab-471b-8204-083a348f2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sequnces(elements, lenght): torch.Size([934, 522])\n",
      "Vocab size (all occuring chords + 2 tokens):  118\n",
      "Chord vocab:------\n",
      " ['<BOS>', '<EOS>', 'A#:dim7', 'A#:hdim7', 'A#:min7', 'A-:7', 'A-:dim7', 'A-:hdim7', 'A-:maj', 'A-:maj7', 'A-:min', 'A-:min7', 'A:7', 'A:dim7', 'A:hdim7', 'A:maj', 'A:maj7', 'A:min', 'A:min7', 'B-:7', 'B-:dim7', 'B-:hdim7', 'B-:maj', 'B-:maj7', 'B-:min', 'B-:min7', 'B:7', 'B:dim7', 'B:hdim7', 'B:maj', 'B:maj7', 'B:min', 'B:min7', 'C#:7', 'C#:dim7', 'C#:hdim7', 'C#:maj', 'C#:maj7', 'C#:min', 'C#:min7', 'C-:7', 'C-:maj', 'C:7', 'C:dim7', 'C:hdim7', 'C:maj', 'C:maj7', 'C:min', 'C:min7', 'D#:7', 'D#:dim7', 'D#:hdim7', 'D#:maj', 'D#:maj7', 'D#:min', 'D#:min7', 'D-:7', 'D-:dim7', 'D-:maj', 'D-:maj7', 'D-:min', 'D-:min7', 'D:7', 'D:dim7', 'D:hdim7', 'D:maj', 'D:maj7', 'D:min', 'D:min7', 'E-:7', 'E-:dim7', 'E-:hdim7', 'E-:maj', 'E-:maj7', 'E-:min', 'E-:min7', 'E:7', 'E:dim7', 'E:hdim7', 'E:maj', 'E:maj7', 'E:min', 'E:min7', 'F#:7', 'F#:dim7', 'F#:hdim7', 'F#:maj', 'F#:maj7', 'F#:min', 'F#:min7', 'F:7', 'F:dim7', 'F:hdim7', 'F:maj', 'F:maj7', 'F:min', 'F:min7', 'G#:7', 'G#:dim7', 'G#:hdim7', 'G#:maj7', 'G#:min', 'G#:min7', 'G-:7', 'G-:dim7', 'G-:hdim7', 'G-:maj', 'G-:maj7', 'G-:min', 'G-:min7', 'G:7', 'G:dim7', 'G:hdim7', 'G:maj', 'G:maj7', 'G:min', 'G:min7'] \n",
      "--------------------\n",
      "Index of BOS: 1\n",
      "Index of EOS: 2\n",
      "{'<BOS>': 1, '<EOS>': 2, 'A#:dim7': 3, 'A#:hdim7': 4, 'A#:min7': 5, 'A-:7': 6, 'A-:dim7': 7, 'A-:hdim7': 8, 'A-:maj': 9, 'A-:maj7': 10, 'A-:min': 11, 'A-:min7': 12, 'A:7': 13, 'A:dim7': 14, 'A:hdim7': 15, 'A:maj': 16, 'A:maj7': 17, 'A:min': 18, 'A:min7': 19, 'B-:7': 20, 'B-:dim7': 21, 'B-:hdim7': 22, 'B-:maj': 23, 'B-:maj7': 24, 'B-:min': 25, 'B-:min7': 26, 'B:7': 27, 'B:dim7': 28, 'B:hdim7': 29, 'B:maj': 30, 'B:maj7': 31, 'B:min': 32, 'B:min7': 33, 'C#:7': 34, 'C#:dim7': 35, 'C#:hdim7': 36, 'C#:maj': 37, 'C#:maj7': 38, 'C#:min': 39, 'C#:min7': 40, 'C-:7': 41, 'C-:maj': 42, 'C:7': 43, 'C:dim7': 44, 'C:hdim7': 45, 'C:maj': 46, 'C:maj7': 47, 'C:min': 48, 'C:min7': 49, 'D#:7': 50, 'D#:dim7': 51, 'D#:hdim7': 52, 'D#:maj': 53, 'D#:maj7': 54, 'D#:min': 55, 'D#:min7': 56, 'D-:7': 57, 'D-:dim7': 58, 'D-:maj': 59, 'D-:maj7': 60, 'D-:min': 61, 'D-:min7': 62, 'D:7': 63, 'D:dim7': 64, 'D:hdim7': 65, 'D:maj': 66, 'D:maj7': 67, 'D:min': 68, 'D:min7': 69, 'E-:7': 70, 'E-:dim7': 71, 'E-:hdim7': 72, 'E-:maj': 73, 'E-:maj7': 74, 'E-:min': 75, 'E-:min7': 76, 'E:7': 77, 'E:dim7': 78, 'E:hdim7': 79, 'E:maj': 80, 'E:maj7': 81, 'E:min': 82, 'E:min7': 83, 'F#:7': 84, 'F#:dim7': 85, 'F#:hdim7': 86, 'F#:maj': 87, 'F#:maj7': 88, 'F#:min': 89, 'F#:min7': 90, 'F:7': 91, 'F:dim7': 92, 'F:hdim7': 93, 'F:maj': 94, 'F:maj7': 95, 'F:min': 96, 'F:min7': 97, 'G#:7': 98, 'G#:dim7': 99, 'G#:hdim7': 100, 'G#:maj7': 101, 'G#:min': 102, 'G#:min7': 103, 'G-:7': 104, 'G-:dim7': 105, 'G-:hdim7': 106, 'G-:maj': 107, 'G-:maj7': 108, 'G-:min': 109, 'G-:min7': 110, 'G:7': 111, 'G:dim7': 112, 'G:hdim7': 113, 'G:maj': 114, 'G:maj7': 115, 'G:min': 116, 'G:min7': 117, 'pad': 0}\n",
      "----------------\n",
      "{1: '<BOS>', 2: '<EOS>', 3: 'A#:dim7', 4: 'A#:hdim7', 5: 'A#:min7', 6: 'A-:7', 7: 'A-:dim7', 8: 'A-:hdim7', 9: 'A-:maj', 10: 'A-:maj7', 11: 'A-:min', 12: 'A-:min7', 13: 'A:7', 14: 'A:dim7', 15: 'A:hdim7', 16: 'A:maj', 17: 'A:maj7', 18: 'A:min', 19: 'A:min7', 20: 'B-:7', 21: 'B-:dim7', 22: 'B-:hdim7', 23: 'B-:maj', 24: 'B-:maj7', 25: 'B-:min', 26: 'B-:min7', 27: 'B:7', 28: 'B:dim7', 29: 'B:hdim7', 30: 'B:maj', 31: 'B:maj7', 32: 'B:min', 33: 'B:min7', 34: 'C#:7', 35: 'C#:dim7', 36: 'C#:hdim7', 37: 'C#:maj', 38: 'C#:maj7', 39: 'C#:min', 40: 'C#:min7', 41: 'C-:7', 42: 'C-:maj', 43: 'C:7', 44: 'C:dim7', 45: 'C:hdim7', 46: 'C:maj', 47: 'C:maj7', 48: 'C:min', 49: 'C:min7', 50: 'D#:7', 51: 'D#:dim7', 52: 'D#:hdim7', 53: 'D#:maj', 54: 'D#:maj7', 55: 'D#:min', 56: 'D#:min7', 57: 'D-:7', 58: 'D-:dim7', 59: 'D-:maj', 60: 'D-:maj7', 61: 'D-:min', 62: 'D-:min7', 63: 'D:7', 64: 'D:dim7', 65: 'D:hdim7', 66: 'D:maj', 67: 'D:maj7', 68: 'D:min', 69: 'D:min7', 70: 'E-:7', 71: 'E-:dim7', 72: 'E-:hdim7', 73: 'E-:maj', 74: 'E-:maj7', 75: 'E-:min', 76: 'E-:min7', 77: 'E:7', 78: 'E:dim7', 79: 'E:hdim7', 80: 'E:maj', 81: 'E:maj7', 82: 'E:min', 83: 'E:min7', 84: 'F#:7', 85: 'F#:dim7', 86: 'F#:hdim7', 87: 'F#:maj', 88: 'F#:maj7', 89: 'F#:min', 90: 'F#:min7', 91: 'F:7', 92: 'F:dim7', 93: 'F:hdim7', 94: 'F:maj', 95: 'F:maj7', 96: 'F:min', 97: 'F:min7', 98: 'G#:7', 99: 'G#:dim7', 100: 'G#:hdim7', 101: 'G#:maj7', 102: 'G#:min', 103: 'G#:min7', 104: 'G-:7', 105: 'G-:dim7', 106: 'G-:hdim7', 107: 'G-:maj', 108: 'G-:maj7', 109: 'G-:min', 110: 'G-:min7', 111: 'G:7', 112: 'G:dim7', 113: 'G:hdim7', 114: 'G:maj', 115: 'G:maj7', 116: 'G:min', 117: 'G:min7', 0: 'pad'}\n"
     ]
    }
   ],
   "source": [
    "from functions.utils import encode_chords\n",
    "\n",
    "chord_vocab, chord_to_idx, idx_to_chord, padded_sequences, vocab_size = encode_chords(all_chords)\n",
    "\n",
    "print(\"Shape of sequnces(elements, lenght):\", padded_sequences.shape)\n",
    "print(\"Vocab size (all occuring chords + 2 tokens): \", vocab_size)\n",
    "print(\"Chord vocab:------\\n\", chord_vocab, \"\\n--------------------\")\n",
    "\n",
    "print(\"Index of BOS:\", chord_to_idx['<BOS>'])\n",
    "print(\"Index of EOS:\", chord_to_idx['<EOS>'])\n",
    "print(chord_to_idx)\n",
    "print(\"----------------\")\n",
    "print(idx_to_chord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc8bb5-1906-43b6-ac06-24689a327e4a",
   "metadata": {},
   "source": [
    "### 1.3 Split Train and Validation\n",
    "Before proceeding with the model, we split our dataset into a training set and a validation set. This will help us evaluate our model's performance on unseen data. This will be archived with pytorch dataloaders. We'll convert our dataset to PyTorch tensors and then create data loaders for training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ecc5cd9-7ff5-417d-b319-526f4732b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, padded_sequences):\n",
    "        self.data = padded_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data[idx]\n",
    "        \n",
    "        # Compute the original length of the sequence (without padding) for pack sequence\n",
    "        length = (sequence != 0).sum().item()  # Count non-zero tokens\n",
    "        \n",
    "        # Using the current token to predict the next token\n",
    "        # So, we return (sequence[:-1], sequence[1:], length - 1)\n",
    "        # We subtract 1 from the length because we're returning sequence[:-1] which has one token less\n",
    "        return sequence[:-1], sequence[1:], length - 1\n",
    "\n",
    "# Create dataset\n",
    "dataset = ChordDataset(padded_sequences)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783113d9-63da-480e-aae0-d1552024a410",
   "metadata": {},
   "source": [
    "## 3. Model Architecture (LSTM)\n",
    "Lets now try the same thing with a LSTM. We will also measure the scores on the same validation set which comes in handy. Since measuring the performance is hard, we have now a way of quantifing the results better.\n",
    "\n",
    "### 3.1 Set up LSTM\n",
    "We will use an embedding layer to represent the integer-encoded chords as dense vectors, followed by an LSTM layer, and then a fully connected layer to produce the predictions for the next chord in the sequence.\n",
    "\n",
    "Our LSTM model consists of the following layers:\n",
    "\n",
    "- Embedding Layer: This converts our integer-encoded chords into dense vectors of fixed size. The embedding layer is beneficial as it allows the model to learn meaningful representations of the chords during training.\n",
    "- LSTM Layer: This layer contains the LSTM cells. We also have n_layers = 2, meaning our LSTM has 2 stacked layers.\n",
    "- Fully Connected Layer: The output from the LSTM layer is passed through a fully connected layer to produce predictions for the next chord in the sequence. The output size is vocab_size which is the size of our vocabulary (including padding and start end tokens\n",
    "  )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0fb2eae-9ecb-421d-81f9-33d4e9aefba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters v2\n",
    "num_epochs = 100\n",
    "embedding_dim = 24#12\n",
    "hidden_dim = 64#24\n",
    "output_dim = vocab_size\n",
    "n_layers = 4#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e59b6f59-773e-4514-a84e-0129b86a080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChordLSTM(\n",
       "  (embedding): Embedding(118, 24)\n",
       "  (lstm): LSTM(24, 64, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=118, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ChordLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout=0.5):\n",
    "        super(ChordLSTM, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # GRU layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, lengths, hidden=None):\n",
    "        # x: (batch_size, sequence_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, sequence_length, embedding_dim)\n",
    "        \n",
    "        # Pack the embedded sequences\n",
    "        packed_embedded = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # GRU output\n",
    "        packed_output, hidden = self.lstm(packed_embedded, hidden)\n",
    "        \n",
    "        # Unpack the output\n",
    "        output, output_lengths = pad_packed_sequence(packed_output, batch_first=True, total_length=x.size(1)) \n",
    "        \n",
    "        # Linear layer\n",
    "        output = self.fc(output)  # (batch_size, sequence_length, output_dim)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "# Initialize the model\n",
    "model = ChordLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout=0.2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcec2c-1d0d-4019-9183-27f69ff8fc42",
   "metadata": {},
   "source": [
    "### 2.2 Train function\n",
    "This one will be used for both models. Cross entrophy will be used and the optimizer will be adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5f71236-2747-4c62-8f56-898dab91538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss: 0.9491 | Validation Loss: 1.3038\n",
      "Epoch 2/100: Train Loss: 0.9420 | Validation Loss: 1.3026\n",
      "Epoch 3/100: Train Loss: 0.9291 | Validation Loss: 1.2937\n",
      "Epoch 4/100: Train Loss: 0.9141 | Validation Loss: 1.2936\n",
      "Epoch 5/100: Train Loss: 0.9058 | Validation Loss: 1.2931\n",
      "Epoch 6/100: Train Loss: 0.9155 | Validation Loss: 1.3056\n",
      "Epoch 7/100: Train Loss: 0.9104 | Validation Loss: 1.3076\n",
      "Epoch 8/100: Train Loss: 0.9181 | Validation Loss: 1.2869\n",
      "Epoch 9/100: Train Loss: 0.9174 | Validation Loss: 1.2945\n",
      "Epoch 10/100: Train Loss: 0.9129 | Validation Loss: 1.2886\n",
      "Epoch 11/100: Train Loss: 0.9108 | Validation Loss: 1.2907\n",
      "Epoch 12/100: Train Loss: 0.9232 | Validation Loss: 1.3166\n",
      "Epoch 13/100: Train Loss: 0.9291 | Validation Loss: 1.2993\n",
      "Epoch 14/100: Train Loss: 0.9145 | Validation Loss: 1.2854\n",
      "Epoch 15/100: Train Loss: 0.9074 | Validation Loss: 1.2899\n",
      "Epoch 16/100: Train Loss: 0.9045 | Validation Loss: 1.2904\n",
      "Epoch 17/100: Train Loss: 0.9217 | Validation Loss: 1.2946\n",
      "Epoch 18/100: Train Loss: 0.9109 | Validation Loss: 1.2867\n",
      "Epoch 19/100: Train Loss: 0.9113 | Validation Loss: 1.2860\n",
      "Epoch 20/100: Train Loss: 0.9121 | Validation Loss: 1.3229\n",
      "Epoch 21/100: Train Loss: 0.9298 | Validation Loss: 1.3094\n",
      "Epoch 22/100: Train Loss: 0.9100 | Validation Loss: 1.3125\n",
      "Epoch 23/100: Train Loss: 0.9016 | Validation Loss: 1.3016\n",
      "Epoch 24/100: Train Loss: 0.9014 | Validation Loss: 1.2996\n",
      "Epoch 25/100: Train Loss: 0.9070 | Validation Loss: 1.2962\n",
      "Epoch 26/100: Train Loss: 0.8984 | Validation Loss: 1.3006\n",
      "Epoch 27/100: Train Loss: 0.8980 | Validation Loss: 1.2928\n",
      "Epoch 28/100: Train Loss: 0.8889 | Validation Loss: 1.2934\n",
      "Epoch 29/100: Train Loss: 0.8958 | Validation Loss: 1.2951\n",
      "Epoch 30/100: Train Loss: 0.8871 | Validation Loss: 1.3124\n",
      "Epoch 31/100: Train Loss: 0.8839 | Validation Loss: 1.3039\n",
      "Epoch 32/100: Train Loss: 0.8918 | Validation Loss: 1.3000\n",
      "Epoch 33/100: Train Loss: 0.8719 | Validation Loss: 1.3102\n",
      "Epoch 34/100: Train Loss: 0.8603 | Validation Loss: 1.3123\n",
      "Epoch 35/100: Train Loss: 0.8761 | Validation Loss: 1.3021\n",
      "Epoch 36/100: Train Loss: 0.8800 | Validation Loss: 1.3281\n",
      "Epoch 37/100: Train Loss: 0.9399 | Validation Loss: 1.3348\n",
      "Epoch 38/100: Train Loss: 0.9327 | Validation Loss: 1.3114\n",
      "Epoch 39/100: Train Loss: 0.9157 | Validation Loss: 1.3080\n",
      "Epoch 40/100: Train Loss: 0.9104 | Validation Loss: 1.3058\n",
      "Epoch 41/100: Train Loss: 0.8940 | Validation Loss: 1.3074\n",
      "Epoch 42/100: Train Loss: 0.8871 | Validation Loss: 1.3147\n",
      "Epoch 43/100: Train Loss: 0.8754 | Validation Loss: 1.3121\n",
      "Epoch 44/100: Train Loss: 0.8776 | Validation Loss: 1.3079\n",
      "Epoch 45/100: Train Loss: 0.8791 | Validation Loss: 1.3080\n",
      "Epoch 46/100: Train Loss: 0.8797 | Validation Loss: 1.3139\n",
      "Epoch 47/100: Train Loss: 0.8689 | Validation Loss: 1.3132\n",
      "Epoch 48/100: Train Loss: 0.8627 | Validation Loss: 1.3103\n",
      "Epoch 49/100: Train Loss: 0.8672 | Validation Loss: 1.3096\n",
      "Epoch 50/100: Train Loss: 0.8609 | Validation Loss: 1.3023\n",
      "Epoch 51/100: Train Loss: 0.8608 | Validation Loss: 1.3104\n",
      "Epoch 52/100: Train Loss: 0.8578 | Validation Loss: 1.3077\n",
      "Epoch 53/100: Train Loss: 0.8533 | Validation Loss: 1.3202\n",
      "Epoch 54/100: Train Loss: 0.8440 | Validation Loss: 1.3055\n",
      "Epoch 55/100: Train Loss: 0.8491 | Validation Loss: 1.3156\n",
      "Epoch 56/100: Train Loss: 0.8428 | Validation Loss: 1.3119\n",
      "Epoch 57/100: Train Loss: 0.8427 | Validation Loss: 1.3166\n",
      "Epoch 58/100: Train Loss: 0.8408 | Validation Loss: 1.3144\n",
      "Epoch 59/100: Train Loss: 0.8560 | Validation Loss: 1.3345\n",
      "Epoch 60/100: Train Loss: 0.8604 | Validation Loss: 1.3295\n",
      "Epoch 61/100: Train Loss: 0.8378 | Validation Loss: 1.3235\n",
      "Epoch 62/100: Train Loss: 0.8605 | Validation Loss: 1.3268\n",
      "Epoch 63/100: Train Loss: 0.8454 | Validation Loss: 1.3271\n",
      "Epoch 64/100: Train Loss: 0.8447 | Validation Loss: 1.3212\n",
      "Epoch 65/100: Train Loss: 0.8619 | Validation Loss: 1.3433\n",
      "Epoch 66/100: Train Loss: 0.9028 | Validation Loss: 1.3483\n",
      "Epoch 67/100: Train Loss: 0.8962 | Validation Loss: 1.3494\n",
      "Epoch 68/100: Train Loss: 0.8898 | Validation Loss: 1.3246\n",
      "Epoch 69/100: Train Loss: 0.8819 | Validation Loss: 1.3234\n",
      "Epoch 70/100: Train Loss: 0.8756 | Validation Loss: 1.3178\n",
      "Epoch 71/100: Train Loss: 0.8950 | Validation Loss: 1.3223\n",
      "Epoch 72/100: Train Loss: 0.8805 | Validation Loss: 1.3207\n",
      "Epoch 73/100: Train Loss: 0.8771 | Validation Loss: 1.3121\n",
      "Epoch 74/100: Train Loss: 0.8623 | Validation Loss: 1.3140\n",
      "Epoch 75/100: Train Loss: 0.8649 | Validation Loss: 1.3192\n",
      "Epoch 76/100: Train Loss: 0.8458 | Validation Loss: 1.3276\n",
      "Epoch 77/100: Train Loss: 0.8473 | Validation Loss: 1.3227\n",
      "Epoch 78/100: Train Loss: 0.8403 | Validation Loss: 1.3283\n",
      "Epoch 79/100: Train Loss: 0.8522 | Validation Loss: 1.3310\n",
      "Epoch 80/100: Train Loss: 0.8408 | Validation Loss: 1.3265\n",
      "Epoch 81/100: Train Loss: 0.8355 | Validation Loss: 1.3237\n",
      "Epoch 82/100: Train Loss: 0.8336 | Validation Loss: 1.3302\n",
      "Epoch 83/100: Train Loss: 0.8321 | Validation Loss: 1.3245\n",
      "Epoch 84/100: Train Loss: 0.8254 | Validation Loss: 1.3311\n",
      "Epoch 85/100: Train Loss: 0.8250 | Validation Loss: 1.3269\n",
      "Epoch 86/100: Train Loss: 0.8249 | Validation Loss: 1.3331\n",
      "Epoch 87/100: Train Loss: 0.8329 | Validation Loss: 1.3360\n",
      "Epoch 88/100: Train Loss: 0.8405 | Validation Loss: 1.3309\n",
      "Epoch 89/100: Train Loss: 0.8421 | Validation Loss: 1.3300\n",
      "Epoch 90/100: Train Loss: 0.8150 | Validation Loss: 1.3274\n",
      "Epoch 91/100: Train Loss: 0.8116 | Validation Loss: 1.3296\n",
      "Epoch 92/100: Train Loss: 0.8250 | Validation Loss: 1.3405\n",
      "Epoch 93/100: Train Loss: 0.8067 | Validation Loss: 1.3389\n",
      "Epoch 94/100: Train Loss: 0.8169 | Validation Loss: 1.3391\n",
      "Epoch 95/100: Train Loss: 0.8104 | Validation Loss: 1.3387\n",
      "Epoch 96/100: Train Loss: 0.8327 | Validation Loss: 1.3457\n",
      "Epoch 97/100: Train Loss: 0.8394 | Validation Loss: 1.3503\n",
      "Epoch 98/100: Train Loss: 0.8467 | Validation Loss: 1.3292\n",
      "Epoch 99/100: Train Loss: 0.8227 | Validation Loss: 1.3490\n",
      "Epoch 100/100: Train Loss: 0.8479 | Validation Loss: 1.3434\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optim --------------------------------------------------------------ASK HEREEE\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# for attention mechanism\n",
    "default_value = 0.3\n",
    "repetition_token = 0.8\n",
    "\n",
    "# Modified training function\n",
    "def train_model(model, train_loader, val_loader, epochs, optimizer, criterion, default_value=0, repetition_token=1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Placeholder for accumulating batch losses\n",
    "        batch_train_losses = []\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for (input_seq, target_seq, lengths) in train_loader:\n",
    "            input_seq, target_seq, lengths = input_seq.to(device), target_seq.to(device), lengths.to(\"cpu\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(input_seq, lengths)\n",
    "\n",
    "            # Reshape output and target_seq for loss computation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            target_seq = target_seq.contiguous().view(-1)\n",
    "            loss = criterion(output, target_seq)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_train_losses.append(loss.item())\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        epoch_train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        batch_val_losses = []\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (input_seq, target_seq, lengths) in val_loader:\n",
    "                input_seq, target_seq, lengths = input_seq.to(device), target_seq.to(device), lengths.to(\"cpu\")\n",
    "\n",
    "                output, _ = model(input_seq, lengths)\n",
    "\n",
    "                # Reshape output and target_seq for loss computation\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output.contiguous().view(-1, output_dim)\n",
    "                target_seq = target_seq.contiguous().view(-1)\n",
    "\n",
    "                val_loss = criterion(output, target_seq)\n",
    "                batch_val_losses.append(val_loss.item())\n",
    "\n",
    "            # Calculate average validation loss for the epoch\n",
    "            epoch_val_loss = sum(batch_val_losses) / len(batch_val_losses)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "\n",
    "        # Print average training and validation loss for the epoch\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {epoch_train_loss:.4f} | Validation Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# Train the GRU model\n",
    "train_losses_lstm, val_losses_lstm = train_model(model, train_loader, val_loader, num_epochs, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53665a19-43a5-414d-b059-8c11fa23d049",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate\n",
    "Evaluate on the whole evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37bdd8c6-8e6b-47bb-be66-7dfc58832248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss (LSTM) on whole validation set:  1.3434069395065307\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (input_seq, target_seq, lenghts) in iterator:\n",
    "            input_seq, target_seq, lenghts = input_seq.to(device), target_seq.to(device), lenghts.to(\"cpu\")\n",
    "\n",
    "            output, _ = model(input_seq, lenghts)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            target_seq = target_seq.contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(output, target_seq)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(iterator)\n",
    "\n",
    "val_loss = evaluate(model, val_loader, criterion, device)\n",
    "print(\"Evaluation Loss (LSTM) on whole validation set: \", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba550b-1c58-4c97-a3f0-7fc8cc821a09",
   "metadata": {},
   "source": [
    "### 2.5 Generate new Sequnces\n",
    "After training our model, we will now use it and generate new sequnces.\n",
    "\n",
    "**Multinomial sampling**:\n",
    "\n",
    "torch.multinomial() function samples values from a multinomial distribution. The function takes in a tensor of probabilities (probs) and an integer which indicates how many samples to draw. In the case of torch.multinomial(probs, 1), it's drawing one sample based on our probabilities.\n",
    "\n",
    "A intuitive way of understanding it:\n",
    "- Imagine you have a weighted dice, where each face of the dice has a different probability of landing face up.\n",
    "- If you  roll this dice, the face that lands up is sampled based on the weights (or probabilities) associated with each face.\n",
    "- torch.multinomial() is doing a similar thing: given a set of probabilities (weights), it's \"rolling the dice\" and returning which \"face\" (index) was chosen.\n",
    "\n",
    "This introduces randomness because, like rolling a weighted dice, you're not guaranteed to get the same outcome every time, even though some outcomes are more probable than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51374f54-5cfd-425e-a915-ed0663f66e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G:hdim7', 'G:hdim7', 'C:7', 'C:7', 'F:min7', 'F:min7', 'F:min7', 'F:min7', 'B:7', 'B:7', 'B:7', 'B:7', 'E:maj7', 'E:maj7', 'E:maj7', 'E:maj7', 'B-:7', 'B-:7', 'B-:7', 'B-:7', 'B-:min7', 'B-:min7', 'B-:min7', 'B-:min7', 'E-:maj', 'E-:maj', 'E-:maj', 'E-:maj', 'B:maj', 'E:dim7', 'E-:min7', 'E-:min7', 'B:7', 'E:dim7', 'C:min7', 'C:min7', 'B-:min7', 'B-:min7', 'E-:min7', 'E-:min7', 'A-:7', 'A-:7', 'B-:7', 'B-:7', 'B-:7', 'B-:7', 'B-:min7', 'B-:min7', 'E-:min7', 'A-:7', 'D-:7', 'D-:7', 'C:7', 'C:7', 'F:7', 'F:7', 'F:min7', 'F:min7', 'B-:7', 'B-:7', 'G:min7', 'G:min7', 'C:7', 'C:7', 'F:min7', 'F:min7', 'B-:7', 'B-:7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'E-:maj7', 'B-:min7', 'B-:min7', 'E-:7', 'E-:7', 'A-:maj', 'A-:maj', 'A-:maj', 'A-:maj', 'D:hdim7', 'D:hdim7', 'G:7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▌                                    | 66/500 [00:26<02:54,  2.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m LSTM_chords_generated \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m)):\n\u001b[0;32m---> 50\u001b[0m     LSTM_chords_generated\u001b[38;5;241m.\u001b[39mappend(map_sequence(\u001b[43mgenerate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m))\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m, in \u001b[0;36mgenerate_sequence\u001b[0;34m(model, start_token, max_length, device, argmax)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Pass input sequence and attention scores to the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Take the last token's probabilities\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m, in \u001b[0;36mChordLSTM.forward\u001b[0;34m(self, x, lengths, hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m packed_embedded \u001b[38;5;241m=\u001b[39m pack_padded_sequence(embedded, lengths, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# GRU output\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m packed_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_embedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Unpack the output\u001b[39;00m\n\u001b[1;32m     25\u001b[0m output, output_lengths \u001b[38;5;241m=\u001b[39m pad_packed_sequence(packed_output, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, total_length\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)) \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:815\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    818\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_sequence(model, start_token, max_length, device, argmax:bool=False):\n",
    "    model.eval()\n",
    "    \n",
    "    generated_sequence = [start_token]\n",
    "    input_seq = torch.LongTensor([start_token]).unsqueeze(0).to(device)\n",
    "    length = torch.tensor([1]).to(\"cpu\")  # initial length is 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "\n",
    "            # Pass input sequence and attention scores to the model\n",
    "            output, _ = model(input_seq, length)\n",
    "            \n",
    "            # Take the last token's probabilities\n",
    "            probabilities = nn.functional.softmax(output[0][-1], dim=0)\n",
    "            \n",
    "            # Sample a token from the distribution\n",
    "            next_token = torch.multinomial(probabilities, 1).item()\n",
    "            \n",
    "            # or use argmax\n",
    "            if argmax:\n",
    "                probabilities = nn.functional.softmax(output[0][-1], dim=0)\n",
    "                next_token = torch.argmax(probabilities).item()\n",
    "\n",
    "            if next_token == 2:  # Check for <EOS>\n",
    "                break\n",
    "            \n",
    "            generated_sequence.append(next_token)\n",
    "            input_seq = torch.LongTensor(generated_sequence).unsqueeze(0).to(device)\n",
    "            length = torch.tensor([len(generated_sequence)]).to(\"cpu\")  # update the length\n",
    "    \n",
    "    return generated_sequence\n",
    "\n",
    "\n",
    "\n",
    "def map_sequence(sequnce, ignore_tokens:bool=True):\n",
    "    str_sequnce = []\n",
    "    for s in sequnce:\n",
    "        str_sequnce.append(idx_to_chord[s])\n",
    "\n",
    "    if ignore_tokens:\n",
    "        return str_sequnce[1:-1]\n",
    "    else:\n",
    "        return str_sequnce\n",
    "\n",
    "print(map_sequence(generate_sequence(model, 1, 1000, device, argmax=False)))\n",
    "\n",
    "LSTM_chords_generated = []\n",
    "for _ in tqdm(range(500)):\n",
    "    LSTM_chords_generated.append(map_sequence(generate_sequence(model, 1, 1000, device, argmax=False)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a8d7ae0-bb5c-4fe6-8385-c754f6692574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_notation(sequence):\n",
    "    repeats = {4: '1', 3: '2.', 2: '2', 1: '4'}\n",
    "    \n",
    "    # Initialize an empty list for results\n",
    "    results = []\n",
    "    \n",
    "    # Start iterating through the sequence\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        count = 1  # At least one occurrence of the chord\n",
    "        chord = sequence[i]\n",
    "        \n",
    "        # Count consecutive repeats\n",
    "        while i + count < len(sequence) and sequence[i + count] == chord:\n",
    "            count += 1\n",
    "        \n",
    "        # Handle the special case where count is 5\n",
    "        if count == 5:\n",
    "            results.append(f\"1{chord}\")\n",
    "            results.append(f\"4{chord}\")\n",
    "            i += 5\n",
    "            continue\n",
    "        \n",
    "        # Check for the chord spanning over a new measure\n",
    "        measure_position = i % 4\n",
    "        if measure_position + count > 4:\n",
    "            # Number of beats the chord is played in the current measure\n",
    "            beats_in_current_measure = 4 - measure_position\n",
    "            # Number of beats the chord is played in the next measure\n",
    "            beats_in_next_measure = count - beats_in_current_measure\n",
    "            \n",
    "            results.append(f\"{repeats[beats_in_current_measure]}{chord}\")\n",
    "            results.append(f\"{repeats[beats_in_next_measure]}{chord}\")\n",
    "            i += count\n",
    "            continue\n",
    "        \n",
    "        # Add the transformed chord to the results for other cases\n",
    "        results.append(f\"{repeats[count]}{chord}\")\n",
    "        \n",
    "        # Move to the next different chord\n",
    "        i += count\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test the function\n",
    "test_sequence1 = ['A:min', 'A:min', 'A:min', 'A:min', 'A:min']\n",
    "test_sequence2 = ['A:min', 'A:min', 'A:min', 'B:min']\n",
    "test_sequence3 = ['A:min', 'B:min', 'C:min', 'D:min']\n",
    "test_sequence4 = ['A:min', 'A:min', 'B:min', 'B:min', 'B:min', 'B:min']\n",
    "test_sequence5 = ['A:min', 'A:min', 'B:min', 'B:min', 'B:min', 'B:min', 'C:min', 'C:min',  'C:min',  'C:min',  'C:min',  'C:min',  'C:min']\n",
    "test_cases = [\n",
    "    test_sequence1,\n",
    "    test_sequence2,\n",
    "    test_sequence3,\n",
    "    test_sequence4,\n",
    "    test_sequence5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64e1ca32-836d-42d2-92ec-2cfb7a097640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A:min', 'A:min', 'A:min', 'A:min', 'A:min']\n",
      "['1A:min', '4A:min']\n",
      "['A:min', 'A:min', 'A:min', 'B:min']\n",
      "['2.A:min', '4B:min']\n",
      "['A:min', 'B:min', 'C:min', 'D:min']\n",
      "['4A:min', '4B:min', '4C:min', '4D:min']\n",
      "['A:min', 'A:min', 'B:min', 'B:min', 'B:min', 'B:min']\n",
      "['2A:min', '2B:min', '2B:min']\n",
      "['A:min', 'A:min', 'B:min', 'B:min', 'B:min', 'B:min', 'C:min', 'C:min', 'C:min', 'C:min', 'C:min', 'C:min', 'C:min']\n",
      "['2A:min', '2B:min', '2B:min', '2C:min', '1C:min', '4C:min']\n",
      "['A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min']\n",
      "['1A:min', '1A:min', '4A:min']\n",
      "['A:min', 'A:min', 'A:min', 'B:min', 'B:min', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'D:maj']\n",
      "['2.A:min', '4B:min', '4B:min', '2.C:maj', '4C:maj', '4D:maj']\n",
      "['A:min']\n",
      "['4A:min']\n",
      "['A:min', 'A:min']\n",
      "['2A:min']\n",
      "['A:min', 'A:min', 'A:min']\n",
      "['2.A:min']\n",
      "['A:min', 'A:min', 'B:min', 'B:min', 'C:maj', 'C:maj', 'D:maj', 'D:maj']\n",
      "['2A:min', '2B:min', '2C:maj', '2D:maj']\n",
      "['A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min']\n",
      "['1A:min', '2.A:min']\n",
      "['A:min', 'B:min', 'C:maj', 'D:maj', 'E:maj', 'F:maj']\n",
      "['4A:min', '4B:min', '4C:maj', '4D:maj', '4E:maj', '4F:maj']\n"
     ]
    }
   ],
   "source": [
    "def merge_chords(chords):\n",
    "    grid = ['4', '2', '2.', '1']\n",
    "    repeats = {'1': 4, '2': 2, '4': 1, '2.': 3}\n",
    "\n",
    "    merged = []\n",
    "    i = 0\n",
    "    while i < len(chords):\n",
    "        measure_fill = 0  # Counter to track current measure's fill level\n",
    "        chord_sequence = []\n",
    "\n",
    "        # Fill up the measure with chords\n",
    "        while i < len(chords) and measure_fill < 4:\n",
    "            chord = chords[i]\n",
    "            chord_sequence.append(chord)\n",
    "            measure_fill += 1\n",
    "            i += 1\n",
    "        \n",
    "        # Process the chord sequence to merge similar adjacent chords\n",
    "        j = 0\n",
    "        while j < len(chord_sequence):\n",
    "            count = chord_sequence[j:].count(chord_sequence[j])\n",
    "            duration = max([k for k, v in repeats.items() if v <= count], key=repeats.get, default='4')\n",
    "            merged.append(duration + chord_sequence[j])\n",
    "            j += repeats[duration]\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test function \n",
    "test = True\n",
    "\n",
    "if test:\n",
    "    # Test the function with the provided examples\n",
    "    merged_chords = [merge_chords(tc) for tc in test_cases]\n",
    "\n",
    "    additional_test_cases = [\n",
    "        # Continuous repeating chords spanning multiple measures\n",
    "        ['A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min'],\n",
    "        \n",
    "        # Mix of different chords with various lengths\n",
    "        ['A:min', 'A:min', 'A:min', 'B:min', 'B:min', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'D:maj'],\n",
    "        \n",
    "        # Single chords\n",
    "        ['A:min'],\n",
    "        ['A:min', 'A:min'],\n",
    "        ['A:min', 'A:min', 'A:min'],\n",
    "        \n",
    "        # Chords with half-measure durations\n",
    "        ['A:min', 'A:min', 'B:min', 'B:min', 'C:maj', 'C:maj', 'D:maj', 'D:maj'],\n",
    "        \n",
    "        # Chords that don't fit exactly into the provided durations\n",
    "        ['A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min'],\n",
    "        \n",
    "        # Mix of different chords with only one occurrence each\n",
    "        ['A:min', 'B:min', 'C:maj', 'D:maj', 'E:maj', 'F:maj']\n",
    "    ]\n",
    "    \n",
    "    merged_additional_chords = [merge_chords(tc) for tc in additional_test_cases]\n",
    "    for inp, result in zip(test_cases + additional_test_cases, merged_chords + merged_additional_chords):\n",
    "        print(inp)\n",
    "        print(result)\n",
    "        #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372671b9-2a05-456a-8b7a-d23ed8b39366",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "\n",
    "### 4.1 Compare losses \n",
    "Lets compare the losses of each network over the epochs. We wil also consider the validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edf0aa8e-7396-40bc-b73a-0e4cb0234a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses_lstm, label='LSTM Training Loss', color='blue')\n",
    "plt.plot(val_losses_lstm, label='LSTM Validation Loss', color='red')\n",
    "plt.title('Training and Validation Losses for LSTM')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig('img/train_results_compare-50epochs.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c884e02-a9e7-4f6d-82e4-a922969598f8",
   "metadata": {},
   "source": [
    "### 4.2 Chord Distribution analysis\n",
    "Lets dive into our generated sequnces and look at some important things of our data.\n",
    "\n",
    "#### 4.2.1 Chord Distribution similartity \n",
    "This function will give a similarity score (**Jensen-Shannon**) between the generated chord distribution and the reference chord distribution. A score of 1 means they are identical, and a score of 0 means they are completely different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eba1d61e-6222-44f2-838b-4e0ff025cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test similartity function:  0.690803316726986\n",
      "LSTM Similartity to dataset:  0.835486687056515\n"
     ]
    }
   ],
   "source": [
    "def chord_distribution_similarity(generated_chords, reference_chords, chord_mapping):\n",
    "    \"\"\"\n",
    "    Compares the distribution of generated chords with a reference distribution using Jensen-Shannon distance.\n",
    "    \n",
    "    Parameters:\n",
    "    - generated_chords: List of chord progressions from the model.\n",
    "    - reference_chords: List of reference chord progressions.\n",
    "    - chord_mapping: Dictionary mapping chord names to indices.\n",
    "    \n",
    "    Returns:\n",
    "    - similarity_score: A value between 0 and 1 indicating the similarity \n",
    "                        between the distributions (1 means they are identical).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the chord progressions into a single list\n",
    "    generated_flat = [chord for progression in generated_chords for chord in progression]\n",
    "    reference_flat = [chord for progression in reference_chords for chord in progression]\n",
    "    \n",
    "    # Get frequency distributions\n",
    "    generated_freq = Counter(generated_flat)\n",
    "    reference_freq = Counter(reference_flat)\n",
    "    \n",
    "    # Convert chord frequencies to probability vectors\n",
    "    num_chords = len(chord_mapping)\n",
    "    generated_probs = [generated_freq.get(chord, 0) / len(generated_flat) for chord in chord_mapping.keys()]\n",
    "    reference_probs = [reference_freq.get(chord, 0) / len(reference_flat) for chord in chord_mapping.keys()]\n",
    "    \n",
    "    # Calculate Jensen-Shannon distance using scipy\n",
    "    js_distance = jensenshannon(generated_probs, reference_probs)\n",
    "    \n",
    "    # Convert the distance to a similarity score\n",
    "    similarity_score = 1 - js_distance\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "    \n",
    "# for testing\n",
    "print(\"Test similartity function: \", chord_distribution_similarity([[\"A:min\", \"A:min\"], [\"A:min\", \"A:min\"]], [[\"A:min\", \"A:min\"], [\"A:min\", \"B:min\"]], chord_to_idx))\n",
    "#print(\"GRU Similartity to dataset: \", chord_distribution_similarity(GRU_chords_generated, all_chords, chord_to_idx))\n",
    "print(\"LSTM Similartity to dataset: \", chord_distribution_similarity(LSTM_chords_generated, all_chords, chord_to_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd458d9-f39c-4acd-b1fd-eb332adc9250",
   "metadata": {},
   "source": [
    "#### 4.2.2 Padding token content\n",
    "The padding tokens are sometimes prediced (especially for the LSTM). lets see how many times we predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeaba520-6078-471c-83d7-e8d9e7a8ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding predicted by LSTM:  0.0\n"
     ]
    }
   ],
   "source": [
    "def percentage_of_pads(data):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of \"pad\" tokens in the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: 2D list containing sequences of strings.\n",
    "\n",
    "    Returns:\n",
    "    - Percentage of \"pad\" tokens in the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_elements = sum(len(sequence) for sequence in data)\n",
    "    pad_count = sum(sequence.count(\"pad\") for sequence in data)\n",
    "    \n",
    "    return (pad_count / total_elements) \n",
    "\n",
    "\n",
    "#gru_pad_percentage = percentage_of_pads(GRU_chords_generated)\n",
    "lstm_pad_percentage = percentage_of_pads(LSTM_chords_generated)\n",
    "\n",
    "#print(\"Padding predicted by GRU: \" , gru_pad_percentage)\n",
    "print(\"Padding predicted by LSTM: \" , lstm_pad_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa223a5-a20b-49fe-89eb-4734b2b0d5d8",
   "metadata": {},
   "source": [
    "#### 4.2.3 Maj/Min Percentages \n",
    "Lets compare the percentage of maj/min chords in our generated dataset with the original ones and new ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cd9be26-25ed-4fbd-9505-9cb3331ca14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM minor chord percentage:  3.362930077691454 | LSTM major chord percentage:  10.9322974472808\n",
      "original minor chord percentage:  4.62853456617568 | Original major chord percentage:  9.44214907767214\n"
     ]
    }
   ],
   "source": [
    "def percentage_of_min_maj(data):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of \":min\" and \":maj\" tokens in the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: 2D list containing sequences of strings.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing (Percentage of \":min\" tokens, Percentage of \":maj\" tokens) in the data.\n",
    "    \"\"\"\n",
    "    # exclude pad, bos and eos tokens\n",
    "    total_elements = sum(1 for sequence in data for chord in sequence if chord not in [\"pad\", \"<BOS>\", \"<EOS>\"])\n",
    "\n",
    "    min_count = sum(chord.endswith(\":min\") for sequence in data for chord in sequence)\n",
    "    maj_count = sum(chord.endswith(\":maj\") for sequence in data for chord in sequence)\n",
    "    \n",
    "    return (min_count / total_elements) * 100, (maj_count / total_elements) * 100\n",
    "\n",
    "#gru_min_percentage, gru_maj_percentage = percentage_of_min_maj(GRU_chords_generated)\n",
    "lstm_min_percentage, lstm_maj_percentage = percentage_of_min_maj(LSTM_chords_generated)\n",
    "ori_min_percentage, ori_maj_percentage = percentage_of_min_maj(all_chords)\n",
    "\n",
    "\n",
    "#print(\"GRU minor chord percentage: \",gru_min_percentage,  \"| GRU major chord percentage: \", gru_maj_percentage)\n",
    "print(\"LSTM minor chord percentage: \",lstm_min_percentage,  \"| LSTM major chord percentage: \", lstm_maj_percentage)\n",
    "print(\"original minor chord percentage: \",ori_min_percentage,  \"| Original major chord percentage: \", ori_maj_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804596c-e033-4872-9ee7-dbff0d790b31",
   "metadata": {},
   "source": [
    "### 4.3 Exporting Sequences as MIDI\n",
    "\n",
    "In this section, we'll utilize the Python library `pretty_midi` to export our chord sequences into MIDI files. These files can be played using the Windows media player or imported into any Digital Audio Workstation (DAW) for playback and further processing.\n",
    "\n",
    "#### 4.3.1 Output Chords only\n",
    "Here, we will output the chord progression with the instrument piano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ec33856-0d95-42bb-80dd-8087b04d7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1E-:maj', '1E-:maj7', '1A:min7', '1D:7', '2G:maj', '4B:dim7', '4G:dim7', '2E:min7', '2A:7', '2A:min7', '2D:7', '1G:7', '1B:7', '2E:min7', '2A:7', '1B:7', '1F:min7', '1B-:7', '1E-:maj7', '1G:7', '2C:maj7', '2G:min7', '2G:maj', '2G:7', '2C:min7', '2F:7', '2B-:maj7', '4B-:dim7', '4D-:dim7', '2F:maj', '2B-:maj7', '1B-:7', '2E-:maj7', '2C:min7', '1C:7', '1C:min7', '1F:7', '1B-:7', '1A:7', '2D:7', '2A:min7', '2B:hdim7', '2E:7', '2A:hdim7', '2D:7', '2.G:maj']\n"
     ]
    }
   ],
   "source": [
    "def chord_to_notes(chord_name):\n",
    "    \"\"\"Converts a chord to a list of the notes (integers) for defining the chord as MIDI. \n",
    "    This version works for the extended vocabulary including major, minor, 7th, major 7th, and minor 7th chords.\"\"\"\n",
    "    \n",
    "    note_name_to_num = {\n",
    "        'C': 60, 'C#': 61, 'D': 62, 'D#': 63, 'E': 64, 'F': 65, \n",
    "        'F#': 66, 'G': 67, 'G#': 68, 'A': 69, 'A#': 70, 'B': 71,\n",
    "        'E-': 63, 'A-': 68, 'B-': 70, 'D-': 61, 'G-': 66  # Adding the flat notes\n",
    "    }\n",
    "    \n",
    "    # Extract the root note and the type (major/minor/7th/maj7/min7) from the chord name\n",
    "    # maj chords have no maj at the and, e.g. F -> F:maj\n",
    "    root, chord_type = chord_name.split(':')\n",
    "    \n",
    "    # Calculate the MIDI numbers for the root, third, fifth, and possibly seventh notes\n",
    "    root_num = note_name_to_num[root]\n",
    "    if \"min\" in chord_type:\n",
    "        third_num = root_num + 3\n",
    "    else:\n",
    "        third_num = root_num + 4\n",
    "    fifth_num = root_num + 7\n",
    "    \n",
    "    # Depending on the chord type, add the seventh note\n",
    "    if \"7\" in chord_type and \"maj7\" not in chord_type:\n",
    "        seventh_num = root_num + 10  # Dominant seventh\n",
    "    elif \"maj7\" in chord_type:\n",
    "        seventh_num = root_num + 11  # Major seventh\n",
    "    else:\n",
    "        seventh_num = None\n",
    "    \n",
    "    notes = [root_num, third_num, fifth_num]\n",
    "    if seventh_num:\n",
    "        notes.append(seventh_num)\n",
    "    \n",
    "    return notes\n",
    "\n",
    "\n",
    "def progression_to_midi(chord_progression, filename='output.mid'):\n",
    "    \"\"\"Creates a midi file and saves it.\"\"\"\n",
    "    # Create a new PrettyMIDI object\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=80)\n",
    "    \n",
    "    # Create an instrument instance for a piano (instrument number 0)\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    piano = pretty_midi.Instrument(program=piano_program)\n",
    "    \n",
    "    # Dictionary to map rhythm prefixes to their duration\n",
    "    rhythm_to_duration = {\n",
    "        '1': 4,\n",
    "        '2.': 3,\n",
    "        '2': 2,\n",
    "        '4': 1\n",
    "    }\n",
    "    \n",
    "    current_time = 0  # Keeps track of the current end time for each chord\n",
    "    \n",
    "    # Iterate over the chord progression and add each chord to the MIDI file\n",
    "    for chord in chord_progression:\n",
    "        if chord not in ['<BOS>', '<EOS>', 'pad']:  # Ignore these tokens\n",
    "            \n",
    "            # Extract rhythm and chord name\n",
    "            if chord[1] == '.':\n",
    "                rhythm = chord[:2]\n",
    "            else: \n",
    "                rhythm = chord[0]\n",
    "            chord_name = chord[len(rhythm):]  # The rest of the string after removing the rhythm\n",
    "            \n",
    "            # Calculate start and end times based on rhythm\n",
    "            start_time = current_time\n",
    "            end_time = start_time + rhythm_to_duration[rhythm]\n",
    "            \n",
    "            # Convert chord name to MIDI notes\n",
    "            notes = chord_to_notes(chord_name)\n",
    "            \n",
    "            # Add each note in the chord to the MIDI file\n",
    "            for note_num in notes:\n",
    "                note = pretty_midi.Note(velocity=100, pitch=note_num, start=start_time, end=end_time)\n",
    "                piano.notes.append(note)\n",
    "            \n",
    "            # Update the current time to the end time of this chord\n",
    "            current_time = end_time\n",
    "    \n",
    "    # Add the piano instrument to the PrettyMIDI object\n",
    "    midi_data.instruments.append(piano)\n",
    "    \n",
    "    # Write out the MIDI data to a file\n",
    "    midi_data.write(filename)\n",
    "\n",
    "\n",
    "# Test the function\n",
    "chord_progression = merge_chords(LSTM_chords_generated[0])\n",
    "print(chord_progression)\n",
    "progression_to_midi(chord_progression, \"test2.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac13616c-525d-43ce-bde8-2dce04a69ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_random_progression_to_midi(chord_progressions, filename_prefix=\"midi/piano/\", model=\"gru\"):\n",
    "    # Pick a random progression from the list\n",
    "    random_progression = random.choice(chord_progressions)\n",
    "    \n",
    "    # Get the ID (index) of the progression\n",
    "    progression_id = chord_progressions.index(random_progression)\n",
    "    \n",
    "    # Create filename\n",
    "    filename = filename_prefix + model + \"-\" + str(progression_id) + \".mid\"\n",
    "    \n",
    "    # Save the progression to MIDI\n",
    "    progression_to_midi(random_progression, filename)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5935bbbc-7870-4300-9676-20fbeb20fe6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRU_chords_generated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m save_random_progression_to_midi(\u001b[43mGRU_chords_generated\u001b[49m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m save_random_progression_to_midi(LSTM_chords_generated, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GRU_chords_generated' is not defined"
     ]
    }
   ],
   "source": [
    "save_random_progression_to_midi(GRU_chords_generated, model=\"gru\")\n",
    "save_random_progression_to_midi(LSTM_chords_generated, model=\"lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca1587-15e8-4359-82e7-79b296d66c7c",
   "metadata": {},
   "source": [
    "#### 4.3.2 JazzArrangement\n",
    "Now the same, but a Jazz since we have a Jazz dataset (*・‿・)ノ⌒*:･ﾟ✧ \n",
    "\n",
    "**Jazz Instruments:**\n",
    "\n",
    "- For the bass, we use the Acoustic Bass instrument.\n",
    "- For the chord instrument, we use the `Electric Piano 1` instrument to give it a Rhodes-like sound.\n",
    "- Keep the piano for the arpeggio but will adjust the velocity to give it a softer touch.\n",
    "\n",
    "**Jazz Drum Pattern:**\n",
    "\n",
    "- Make the drum pattern swing a bit to give it a jazz feel.\n",
    "- Use the Ride Cymbal 1 for the on-beats and the Side Stick for the off-beats to create a simple jazz rhythm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "badc1b18-a906-40c2-b6e3-a61dcef3c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_progression_to_midi_jazz(chord_progression, filename='output.mid', bpm=120):\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=bpm)\n",
    "\n",
    "    # Jazz Instruments\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    bass_program = pretty_midi.instrument_name_to_program('Acoustic Bass')\n",
    "    chord_program = pretty_midi.instrument_name_to_program('Electric Piano 1')\n",
    "    \n",
    "    piano = pretty_midi.Instrument(program=piano_program)\n",
    "    bass = pretty_midi.Instrument(program=bass_program)\n",
    "    chords = pretty_midi.Instrument(program=chord_program)\n",
    "    drums = pretty_midi.Instrument(program=0, is_drum=True)\n",
    "    \n",
    "    # Jazz Drum patterns\n",
    "    RIDE_CYMBAL = 51  # MIDI number for Ride Cymbal 1\n",
    "    SIDE_STICK = 37   # MIDI number for Side Stick\n",
    "    \n",
    "    # Mapping of duration prefixes to their respective durations\n",
    "    rhythm_to_duration = {'1': 4, '2.': 3, '2': 2, '4': 1}\n",
    "    \n",
    "    # Time tracker\n",
    "    current_time = 0\n",
    "\n",
    "    # Iterate over the chord progression\n",
    "    for chord in chord_progression:\n",
    "        if chord not in ['<BOS>', '<EOS>', 'pad']:  # Ignore these tokens\n",
    "            \n",
    "            # Extract rhythm and chord name\n",
    "            if chord[1] == '.':\n",
    "                rhythm = chord[:2]\n",
    "            else: \n",
    "                rhythm = chord[0]\n",
    "            chord_name = chord[len(rhythm):]  # The rest of the string after removing the rhythm\n",
    "            duration = rhythm_to_duration[rhythm]\n",
    "\n",
    "            start_time = current_time\n",
    "            end_time = start_time + duration\n",
    "            \n",
    "            # Chord notes\n",
    "            notes = chord_to_notes(chord_name)\n",
    "            \n",
    "            # Bass note (root of the chord)\n",
    "            bass_note = pretty_midi.Note(velocity=127, pitch=notes[0]-12, start=start_time, end=end_time)\n",
    "            bass.notes.append(bass_note)\n",
    "            \n",
    "            # Chord\n",
    "            for note_num in notes:\n",
    "                chord_note = pretty_midi.Note(velocity=70, pitch=note_num, start=start_time, end=end_time)\n",
    "                chords.notes.append(chord_note)\n",
    "            \n",
    "            # Piano Arpeggio (adjusted to 1/2 note)\n",
    "            arpeggio_duration = 0.5\n",
    "            arpeggio_start = start_time\n",
    "            while arpeggio_start < end_time:\n",
    "                for j, note_num in enumerate(notes):\n",
    "                    if arpeggio_start + j*arpeggio_duration >= end_time:\n",
    "                        break  # Stop if we exceed the chord's end time\n",
    "                    arpeggio_note = pretty_midi.Note(velocity=60, pitch=note_num, \n",
    "                                                     start=arpeggio_start + j*arpeggio_duration, \n",
    "                                                     end=arpeggio_start + (j+1)*arpeggio_duration)\n",
    "                    piano.notes.append(arpeggio_note)\n",
    "                arpeggio_start += len(notes) * arpeggio_duration\n",
    "            \n",
    "            # Jazz Drums pattern (only every 1/2 measure)\n",
    "            drum_ride_intervals = [0, 0.5]\n",
    "            drum_ride_start = start_time\n",
    "            while drum_ride_start < end_time:\n",
    "                for interval in drum_ride_intervals:\n",
    "                    if drum_ride_start + interval >= end_time:\n",
    "                        break  # Stop if we exceed the chord's end time\n",
    "                    drum_ride = pretty_midi.Note(velocity=80, pitch=RIDE_CYMBAL, start=drum_ride_start + interval, end=drum_ride_start + interval + 0.1)\n",
    "                    drums.notes.append(drum_ride)\n",
    "                drum_ride_start += 1  # Increment by a whole measure for the next cycle\n",
    "\n",
    "            # Update the current time\n",
    "            current_time = end_time\n",
    "    \n",
    "    # Add the instruments to the PrettyMIDI object\n",
    "    midi_data.instruments.extend([piano, bass, chords, drums])\n",
    "    \n",
    "    # Write out the MIDI data to a file\n",
    "    midi_data.write(filename)\n",
    "\n",
    "\n",
    "\n",
    "# For testing purposes\n",
    "enhanced_progression_to_midi_jazz(chord_progression, \"test_enhancedJAZZ2.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae64c4f-b730-4a34-b154-3a8913af2ba4",
   "metadata": {},
   "source": [
    "#### WITH SAXOPHOOONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cb7e1de-7cba-4362-b045-590854c763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_progression_to_midi_jazz(chord_progression, filename='output.mid', bpm=120):\n",
    "    \"\"\"LETSSS GOOOOO. i should probably go to sleep.\"\"\"\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=bpm)\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    bass_program = pretty_midi.instrument_name_to_program('Acoustic Bass')\n",
    "    chord_program = pretty_midi.instrument_name_to_program('Electric Piano 1')\n",
    "    \n",
    "    piano = pretty_midi.Instrument(program=piano_program)\n",
    "    bass = pretty_midi.Instrument(program=bass_program)\n",
    "    chords = pretty_midi.Instrument(program=chord_program)\n",
    "    drums = pretty_midi.Instrument(program=0, is_drum=True)\n",
    "    \n",
    "    RIDE_CYMBAL = 51\n",
    "    SIDE_STICK = 37\n",
    "    rhythm_to_duration = {'1': 4, '2.': 3, '2': 2, '4': 1}\n",
    "    current_time = 0\n",
    "\n",
    "    sax_program = pretty_midi.instrument_name_to_program('Alto Sax')\n",
    "    sax = pretty_midi.Instrument(program=sax_program)\n",
    "    major_scale_intervals = [2, 2, 1, 2, 2]\n",
    "    minor_scale_intervals = [2, 1, 2, 2, 2]\n",
    "\n",
    "    for chord in chord_progression:\n",
    "        if chord not in ['<BOS>', '<EOS>', 'pad']:\n",
    "            if chord[1] == '.':\n",
    "                rhythm = chord[:2]\n",
    "            else: \n",
    "                rhythm = chord[0]\n",
    "            chord_name = chord[len(rhythm):]\n",
    "            duration = rhythm_to_duration[rhythm]\n",
    "            start_time = current_time\n",
    "            end_time = start_time + duration\n",
    "            \n",
    "            notes = chord_to_notes(chord_name)\n",
    "            bass_note = pretty_midi.Note(velocity=127, pitch=notes[0]-12, start=start_time, end=end_time)\n",
    "            bass.notes.append(bass_note)\n",
    "            \n",
    "            for note_num in notes:\n",
    "                chord_note = pretty_midi.Note(velocity=70, pitch=note_num, start=start_time, end=end_time)\n",
    "                chords.notes.append(chord_note)\n",
    "            \n",
    "            arpeggio_duration = 0.5\n",
    "            arpeggio_times = int(duration/arpeggio_duration)\n",
    "            for j in range(arpeggio_times):\n",
    "                for k, note_num in enumerate(notes):\n",
    "                    arpeggio_note = pretty_midi.Note(velocity=60, pitch=note_num, start=start_time + j*len(notes)*arpeggio_duration + k*arpeggio_duration, end=start_time + j*len(notes)*arpeggio_duration + (k+1)*arpeggio_duration)\n",
    "                    piano.notes.append(arpeggio_note)\n",
    "            \n",
    "            for j in range(int(duration)):\n",
    "                drum_ride = pretty_midi.Note(velocity=80, pitch=RIDE_CYMBAL, start=start_time + j, end=start_time + j + 0.1)\n",
    "                drum_side_stick = pretty_midi.Note(velocity=70, pitch=SIDE_STICK, start=start_time + j + 0.5, end=start_time + j + 0.55)\n",
    "                drums.notes.append(drum_ride)\n",
    "                if j % 3 == 0:\n",
    "                    drums.notes.append(drum_side_stick)\n",
    "\n",
    "            root_note = chord_to_notes(chord_name)[0]\n",
    "            if \"min\" in chord_name:\n",
    "                scale = [root_note]\n",
    "                for interval in minor_scale_intervals:\n",
    "                    root_note += interval\n",
    "                    scale.append(root_note)\n",
    "            else:\n",
    "                scale = [root_note]\n",
    "                for interval in major_scale_intervals:\n",
    "                    root_note += interval\n",
    "                    scale.append(root_note)\n",
    "        \n",
    "            sax_melody = generate_sax_melody(scale, start_time, end_time)\n",
    "            for note, start, end in sax_melody:\n",
    "                sax_note = pretty_midi.Note(velocity=90, pitch=note, start=start, end=end)\n",
    "                sax.notes.append(sax_note)\n",
    "        \n",
    "            current_time = end_time\n",
    "    \n",
    "    midi_data.instruments.extend([piano, bass, chords, drums, sax])\n",
    "    midi_data.write(filename)\n",
    "\n",
    "def generate_sax_melody(scale, start_time, end_time):\n",
    "    \"\"\"This is purley experimental since im very much hyped by the results and cant belive how well they sound. \"\"\"\n",
    "    # Different note durations for the melody and their probabilities\n",
    "    durations = [0.25, 0.5, 0.75, 1]  # Quarter note, half note, dotted half note, whole note\n",
    "    duration_probs = [0.1, 0.5, 0.2, 0.2]  # Probabilities for each duration\n",
    "    \n",
    "    # Start generating the melody\n",
    "    melody = []\n",
    "    current_time = start_time\n",
    "    while current_time < end_time:\n",
    "        # Randomly choose a note duration\n",
    "        duration = random.choices(durations, duration_probs)[0]\n",
    "        \n",
    "        # Randomly choose whether to play a note or have a rest (break)\n",
    "        play_note = random.choice([True, True, True, False])\n",
    "        \n",
    "        if play_note:\n",
    "            # Randomly choose a note from the scale\n",
    "            note = random.choice(scale)\n",
    "            melody.append((note, current_time, current_time + duration))\n",
    "        \n",
    "        # Move to the next time slot\n",
    "        current_time += duration\n",
    "        \n",
    "    return melody\n",
    "\n",
    "enhanced_progression_to_midi_jazz(chord_progression, \"test_enhancedJAZZ-sax2.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b53c0-62f3-4302-8d39-d59727134e55",
   "metadata": {},
   "source": [
    "### 4.6 Discussion\n",
    "\n",
    "#### 4.6.1 Metrics\n",
    "\n",
    "We observe that, using the same hyper-parameters, both networks perform similarly in terms of convergence and convergence speed. The outputs from both are also quite alike. When compared to the original data, it's evident that both networks produce outputs that are very close, especially in terms of the Jensen-Shannon Divergence. The contents of Minor and Major are also strikingly similar. With the newly implemented pack_padded_sequence from PyTorch, we've completely eliminated the problem of predicting padding. Our predictions now contain 0% padding tokens. Additionally, when setting the sequence length generation limit exceptionally high, the network consistently stops predicting, as it predicts the EOS token, which is desired. The outputs from both networks now seem very reasonable. Training and computation times don't vary significantly; especially on CUDA, we experience fast training times. It's worth noting that this is partly because we set the n_layers parameter relatively low and opted for modest hidden and embedding dimensions. Through testing, these configurations were found to give the best results. Larger dimensions tend to lead to overfitting, and the network struggles to learn the chord progressions, which are relatively straightforward given our small vocabulary size.\n",
    "#### 4.6.2 Personal\n",
    "\n",
    "Listening to the generated audio files, it's clear that both networks produce harmonious chord progressions. They don't sound arbitrary, and at times, they offer cool progressions that are quite popular and recognizable. Without time information, the output feels a bit monotonous, with each bar representing a single chord. Addressing this will be the next milestone in the BA thesis!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
